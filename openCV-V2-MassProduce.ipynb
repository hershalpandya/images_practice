{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import imutils\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "# some global params\n",
    "\n",
    "dpi=90\n",
    "\n",
    "# rootdir=\"/Users/hershalpandya/data/temp_delete/images/livecell_train_val_images/A172//\"\n",
    "# all_image_files=glob.glob(rootdir+\"A172_Phase*00d00h00m*.tif\")\n",
    "# outfile=\"extracted_images_A172.npz\"\n",
    "# output_size=28 # size of the image to be cut out.  in pixels.\n",
    "# blocksize = 5 # for adaptiveThreshold. based on image size and resolution. some sort of smoothing size. keep it odd. \n",
    "# thresholding_binary_value = 3 # for cv2.adaptiveThreshold based on details in the original pic. 3 for high detail... otherwise increase it. keep it odd.\n",
    "# blurring_value=5 # cv2.GaussianBlur\n",
    "\n",
    "\n",
    "rootdir=\"/Users/hershalpandya/data/temp_delete/images/livecell_train_val_images/BT474/\"\n",
    "all_image_files=glob.glob(rootdir+\"*_Phase*00d00h00m*.tif\")\n",
    "outfile=\"extracted_images_BT474.npz\"\n",
    "output_size=12 # size of the image to be cut out.  in pixels.\n",
    "blocksize = 5 # for adaptiveThreshold. based on image size and resolution. some sort of smoothing size. keep it odd. \n",
    "thresholding_binary_value = 3 # for cv2.adaptiveThreshold based on details in the original pic. 3 for high detail... otherwise increase it. keep it odd.\n",
    "blurring_value=1 # cv2.GaussianBlur\n",
    "\n",
    "\n",
    "print (len(all_image_files))\n",
    "# all_image_files=[all_image_files[3]]\n",
    "# print (len(all_image_files))\n",
    "plotfew=False\n",
    "# print (all_image_files)\n",
    "# image_file=all_image_files[1]\n",
    "# print (image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_file=np.random.randint(len(all_image_files))\n",
    "# print (chosen_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_images_array=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_id:  0  n cells found: 263\n",
      "img_id:  1  n cells found: 274\n",
      "img_id:  2  n cells found: 281\n",
      "img_id:  3  n cells found: 250\n",
      "img_id:  4  n cells found: 292\n",
      "img_id:  5  n cells found: 253\n",
      "img_id:  6  n cells found: 235\n",
      "img_id:  7  n cells found: 249\n",
      "img_id:  8  n cells found: 226\n",
      "img_id:  9  n cells found: 292\n",
      "img_id:  10  n cells found: 303\n",
      "img_id:  11  n cells found: 266\n",
      "img_id:  12  n cells found: 230\n",
      "img_id:  13  n cells found: 281\n",
      "img_id:  14  n cells found: 251\n",
      "img_id:  15  n cells found: 260\n",
      "img_id:  16  n cells found: 292\n",
      "img_id:  17  n cells found: 292\n",
      "img_id:  18  n cells found: 303\n",
      "img_id:  19  n cells found: 272\n",
      "img_id:  20  n cells found: 263\n",
      "img_id:  21  n cells found: 279\n",
      "img_id:  22  n cells found: 271\n",
      "img_id:  23  n cells found: 306\n"
     ]
    }
   ],
   "source": [
    "for img_id, image_file in enumerate(all_image_files):\n",
    "#     if img_id!=chosen_file:\n",
    "#         continue\n",
    "    #------------------------\n",
    "    # IMAGE MANIPULATION BEGIN\n",
    "    #------------------------\n",
    "    img = cv2.imread(image_file)\n",
    "\n",
    "    # grayscale the image for normalizing values to 0 to 255\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # renaming variables in case later on you want to change which version of images are used beyond this point:\n",
    "#     img_for_segmenting = img\n",
    "    img_for_finding_centers = np.copy(img)\n",
    "\n",
    "\n",
    "    if plotfew:\n",
    "        plt.figure(dpi = dpi)\n",
    "        plt.title(\"Image for finding Centers\")\n",
    "        plt.imshow(img_for_finding_centers,cmap='gray')\n",
    "        plt.colorbar()\n",
    "    \n",
    "    # apply adaptive threshold for contrasting image.\n",
    "    # both mean and gauss perform almost same. We'll go with gauss.\n",
    "    thresh_gauss = cv2.adaptiveThreshold(img_for_finding_centers, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                              cv2.THRESH_BINARY, thresholding_binary_value, blocksize)\n",
    "\n",
    "#     otsu_threshold, temp = cv2.threshold(img_for_finding_centers, 0, 255, \n",
    "#                                          cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # create a composite image after applying gaussian trheshold \n",
    "    img_for_finding_centers = np.asarray(img_for_finding_centers, np.float64)\n",
    "    mask=np.asarray(img_for_finding_centers>thresh_gauss, np.float64)\n",
    "    \n",
    "    img_for_finding_centers=cv2.multiply(img_for_finding_centers,mask)\n",
    "    img_for_finding_centers/=np.max(img_for_finding_centers)\n",
    "    \n",
    "#     if plotfew:\n",
    "#         plt.figure(dpi = dpi)\n",
    "#         plt.title(\"Image for finding Centers\")\n",
    "#         plt.imshow(img_for_finding_centers,cmap='binary')\n",
    "#         plt.colorbar()\n",
    "    \n",
    "    # blur the image.\n",
    "    img_for_finding_centers  = cv2.GaussianBlur(img_for_finding_centers, (blurring_value, blurring_value), 0)\n",
    "\n",
    "    # dilate the image.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(1,1))\n",
    "    img_for_finding_centers = cv2.dilate(img_for_finding_centers, kernel, iterations=3)\n",
    "    \n",
    "    img_for_segmenting = img\n",
    "\n",
    "    #------------------------\n",
    "    # IMAGE MANIPULATION END\n",
    "    #------------------------\n",
    "    \n",
    "    if plotfew:\n",
    "        plt.figure(dpi = dpi)\n",
    "        plt.title(\"Image for finding Centers\")\n",
    "        plt.imshow(img_for_finding_centers,cmap='binary')\n",
    "        plt.colorbar()\n",
    "\n",
    "    #------------------------\n",
    "    # IMAGE SEGMENTATION BEGIN\n",
    "    #------------------------\n",
    "\n",
    "    # assign labels to the blobs/structures : main segmentation job.\n",
    "    img_to_label = np.copy(img_for_finding_centers)\n",
    "    img_to_label[img_to_label!=0]=1\n",
    "\n",
    "    connectivity = ndimage.generate_binary_structure(2,2)\n",
    "    labels, n_labels = ndimage.label(img_to_label, connectivity)\n",
    "\n",
    "    # find the center location in each blob/structure.\n",
    "    crosses_x_, crosses_y_ = np.array([np.round(np.mean(np.argwhere(labels==i),axis=0),0) for i in range(n_labels)]).T\n",
    "    old_ids_ = np.arange(len(crosses_x_))\n",
    "\n",
    "    # calculate distance to the boundary of the picture. \n",
    "    # create a mask exclude the cells which are cropped during imaging \n",
    "    distance_to_edges = np.array([np.min([crosses_x_[i],\n",
    "                                          crosses_y_[i],\n",
    "                                          np.absolute(crosses_x_[i] - labels.shape[0]), \n",
    "                                          np.absolute(crosses_y_[i] - labels.shape[1])\n",
    "                                         ])\n",
    "                                 for i in range(len(crosses_x_))\n",
    "                                 ])\n",
    "    select_cells = distance_to_edges>output_size\n",
    "\n",
    "\n",
    "    # calculate pairwise distances between crosses. \n",
    "    crosses = np.array([crosses_x_, crosses_y_]).T\n",
    "    pdistances = distance.squareform(distance.pdist(crosses))\n",
    "\n",
    "    keep_one_cross = np.argwhere(pdistances<output_size)\n",
    "    keep_one_cross = np.array([i for i in keep_one_cross if i[0]!=i[1]])\n",
    "\n",
    "    # create a mask to remove blobs labelled too close to each other\n",
    "    # out of two blobs, the bigger one is retained. yay!\n",
    "    remove_crosses=[]\n",
    "    for i in keep_one_cross:\n",
    "\n",
    "        if i[0] in remove_crosses or i[1] in remove_crosses:\n",
    "            continue\n",
    "\n",
    "        s0= np.sum(img_for_finding_centers[labels==i[0]])\n",
    "        s1= np.sum(img_for_finding_centers[labels==i[1]])\n",
    "\n",
    "        if s0<=s1:\n",
    "            remove_crosses.append(i[0])\n",
    "        else:\n",
    "            remove_crosses.append(i[1])\n",
    "\n",
    "    remove_cells2 = np.array([i in remove_crosses for i in range(len(crosses_x_))])\n",
    "    select_cells2 = ~remove_cells2\n",
    "\n",
    "\n",
    "    ## apply mask on crosses and finally find the centers of blobs you want to extract:\n",
    "\n",
    "    crosses_x = crosses_x_[select_cells&select_cells2]\n",
    "    crosses_y = crosses_y_[select_cells&select_cells2]\n",
    "    old_ids = old_ids_[select_cells&select_cells2] # redundancy but for debugging here.\n",
    "\n",
    "\n",
    "    print (\"img_id: \",img_id,\" n cells found:\" ,len(crosses_x))\n",
    "    if plotfew:\n",
    "        #----\n",
    "        # optional plotting\n",
    "        # ---\n",
    "        cid_start=0\n",
    "        cid_stop=len(crosses_y)\n",
    "\n",
    "        plt.figure(dpi=3*dpi)\n",
    "        plt.title(img_id)\n",
    "        plt.imshow(labels,cmap='tab20b_r')\n",
    "        plt.scatter(crosses_y[cid_start:cid_stop], \n",
    "                    crosses_x[cid_start:cid_stop]*1.01,\n",
    "                    s=45,c='w',marker='x',lw=1)\n",
    "        for cid in range(cid_start,cid_stop):\n",
    "            plt.text(crosses_y[cid],\n",
    "                     crosses_x[cid],\n",
    "                     cid,fontsize=8,c='w')\n",
    "\n",
    "        plt.scatter(crosses_y_, crosses_x_,s=5,c='k',marker='.')\n",
    "        for cid in np.arange(len(crosses_y_))[select_cells]:\n",
    "            plt.text(crosses_y_[cid],crosses_x_[cid],\n",
    "                     cid,fontsize=6,c='grey',alpha=0.7)\n",
    "\n",
    "    for i in np.arange(len(crosses_x)):\n",
    "\n",
    "        n=int(crosses_x[i])\n",
    "        m=int(crosses_y[i])\n",
    "\n",
    "        ln=np.max( [n - output_size,0] )\n",
    "        hn=np.min( [n + output_size, img_for_finding_centers.shape[0] ] )\n",
    "\n",
    "        lm=np.max( [m - output_size,0] )\n",
    "        hm=np.min( [m + output_size, img_for_finding_centers.shape[1] ] )\n",
    "\n",
    "        extracted_img = img_for_segmenting[ln:hn,lm:hm]\n",
    "        \n",
    "#         print('Original Dimensions : ',extracted_img.shape)\n",
    " \n",
    "#         scale_percent = 50 # percent of original size\n",
    "#         width = int(extracted_img.shape[1] * scale_percent / 100)\n",
    "#         height = int(extracted_img.shape[0] * scale_percent / 100)\n",
    "#         dim = (width, height)\n",
    "  \n",
    "        # resize image\n",
    "#         extracted_img = cv2.resize(extracted_img, dim, interpolation = cv2.INTER_AREA)\n",
    " \n",
    "#         print('Resized Dimensions : ',extracted_img.shape)\n",
    " \n",
    "        extracted_images_array.append(extracted_img)\n",
    "        \n",
    "        if plotfew and i%4==0:\n",
    "            #------\n",
    "            #optional plotting\n",
    "            #------\n",
    "            cross_x = n\n",
    "            cross_y = m\n",
    "            extent = [ln,hn,lm,hm]\n",
    "            this_img2 = extracted_img\n",
    "            this_img = img_for_finding_centers[ln:hn,lm:hm]\n",
    "\n",
    "            lln=np.max( [n- 2*output_size,0] )\n",
    "            hhn=np.min( [n+ 2*output_size, img_for_finding_centers.shape[0] ] )\n",
    "\n",
    "            llm=np.max( [m- 2*output_size,0] )\n",
    "            hhm=np.min( [m+ 2*output_size, img_for_finding_centers.shape[1] ] )\n",
    "            extent3 = [lln,hhn,llm,hhm]\n",
    "\n",
    "            this_img3 = img_for_segmenting[lln:hhn,llm:hhm]\n",
    "\n",
    "            plt.figure(dpi=dpi,figsize=(10,3))\n",
    "            plt.suptitle(\"new: \"+str(i)+\", old:\"+str(old_ids[i]))\n",
    "\n",
    "            plt.subplot(131)\n",
    "            plt.imshow(this_img,cmap='binary',extent=extent)\n",
    "            plt.scatter([cross_x],[cross_y],s=100,c='r',marker='x',lw=3)\n",
    "\n",
    "            plt.subplot(132)\n",
    "            plt.imshow(this_img2,cmap='binary',extent=extent)\n",
    "            plt.scatter([cross_x],[cross_y],s=100,c='r',marker='x',lw=3)\n",
    "\n",
    "            plt.subplot(133)\n",
    "            plt.imshow(this_img3,cmap='binary',extent=extent3)\n",
    "            plt.scatter([cross_x],[cross_y],s=100,c='r',marker='x',lw=3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6484\n"
     ]
    }
   ],
   "source": [
    "print (len(extracted_images_array))\n",
    "if not plotfew:\n",
    "    np.savez(outfile,images=extracted_images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
